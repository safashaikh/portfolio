{"status":"ok","feed":{"url":"https://medium.com/feed/@safashaikh","title":"Stories by Safa Shaikh on Medium","link":"https://medium.com/@safashaikh?source=rss-2f2ac4879260------2","author":"","description":"Stories by Safa Shaikh on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/0*Mvx1-XHUabnKMLbY"},"items":[{"title":"Optimization Techniques for ML Models","pubDate":"2021-04-27 17:16:10","link":"https://medium.com/geekculture/optimization-techniques-for-ml-models-bd500c8398ce?source=rss-2f2ac4879260------2","guid":"https://medium.com/p/bd500c8398ce","author":"Safa Shaikh","thumbnail":"","description":"\n<p>There are two main areas we can optimize over for many machine learning algorithms and deep learning networks. One is hyperparameters and the second is neural network architecture.</p>\n<p>The selection of hyperparameters is sometimes critical in determining a model\u2019s convergence. Optimization techniques are used to determine what the best hyperparameters are for the learning algorithm. The optimal hyperparameters that correspond to a user defined metric are chosen. Often times optimization is done to minimize the loss of the model or maximize an accuracy. This procedure is known as <strong>Hyperparameter Optimization (HPO).</strong></p>\n<p>Hyperparameter optimization is done over a fixed architecture, but we can also perform a technique called <strong>Network Architecture Search (NAS)</strong>, which performs a search over the architecture space of a ML model or a deep learning network if the model still does not seem to converge after HPO alone. Many times, finding the best architecture can require domain expertise and can be time consuming considering the training and evaluation of multiple versions of the ML model being tested. For example, determining whether to expand the width of a network by adding more hidden nodes or add depth to a network by adding more layers is a problem that can be solved by\u00a0NAS.</p>\n<p>HPO and NAS algorithms can use both white box and black box methods to find the optimal hyperparameters and architecture. White box methods use internal gradients for optimization, so they can typically only be used in models that have a continuous hyperparameter space. Black box methods explore the hyperparameter/architecture space without being concerned about internal gradients so they can be used on any hyperparameter or architecture space. Two black box methods presented below are <a href=\"https://arxiv.org/abs/1206.2944\">Bayesian Optimization</a> and <a href=\"https://arxiv.org/pdf/1905.07350.pdf\">DeepSwarm</a>.</p>\n<h3><strong>Bayesian Optimization</strong></h3>\n<p>The following is a summary of <a href=\"https://papers.nips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf\">Practical Bayesian Optimization of Machine Learning Algorithms</a>.</p>\n<p>The objective of Bayesian Optimization is to find the optimal hyperparameters for a machine learning model. In simple terms this is a unique way to find the minimum of a loss function\u00a0<em>f(x).</em></p>\n<p>This learning algorithm\u2019s generalization performance is modeled as a sample from a Gaussian process (GP). Each GP specified by kernel and hyperparameters and it also takes variable cost and runtime into account for computational parellelization in the\u00a0future.</p>\n<p>Bayesian Optimization is useful for tuning parameters of algorithms that have high computational cost.</p>\n<p>The objective of Bayesian optimization is finding the minimum of <em>f(x)</em> using a probabilistic mode, using all prior evaluations of <em>f(x)</em> to determine location of where to evaluate next instead of local gradients and because evaluations of <em>f(x)</em> are\u00a0costly.</p>\n<p>The two components we need to choose are the Gaussian prior and an acquisition function.</p>\n<h4>Gaussian Process</h4>\n<p>We choose a loss\u00a0function</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/84/0*cWg7dXtYcdqQ7JyQ\"></figure><p>where X is set of hyperparameter settings.</p>\n<p>Then we define a multivariate Gaussian distribution on finite set of N\u00a0points:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/95/0*2i5x3aaCAWoJrbYs\"></figure><p>which induces the distribution on</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/25/0*oGzaWUgqpkhu9dy3\"></figure><p>determined by a mean function and a positive definite covariance function.</p>\n<h4>Acquisition function</h4>\n<p>For the acquisition function we assume data points drawn\u00a0from</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/85/0*J6vzSLtL1ZJBdXrT\"></figure><p>where <em>y</em> is obtained from a normal distribution</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/134/0*8-SgRk_UNxSaNUR5\"></figure><p>and</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/9/0*rpY0_ep6df_hsqCp\"></figure><p>is the variance in the function values. To find the next data point to evaluate in terms of finding the minimum f(x), we\u00a0define</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/159/0*2weJMZycv7QUlZBO\"></figure><p>where <strong>a</strong> represents the acquisition function.</p>\n<p>There are several options to choose from for acquisition function such\u00a0as</p>\n<ul><li>\n<strong>Probability of Improvement\u200a\u2014\u200a</strong>maximize over probability of getting a better value than the best current\u00a0value</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*9mz9vFNGV2XCEGfDVadsyw.png\"></figure><ul><li>\n<strong>Expected Improvement\u200a\u2014\u200a</strong>maximize expected improvement over current\u00a0best</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/1*q-_u1lbZTkPY7Jk-3QRa4Q.png\"></figure><ul><li>Gamma is defined\u00a0as</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/259/1*JqDWftsCGoUibdk42rCMEg.png\"></figure><h4>Modeling costs</h4>\n<p>We need to find best setting of hyperparameters quickly\u200a\u2014\u200awe are more concerned with wall clock time than function progress.</p>\n<p>We optimize with <strong>expected improvement per second</strong>\u200a\u2014\u200apoints that are likely to be good and likely to be evaluated quickly (e.g. choosing from a set of faster learning rates over slower\u00a0ones)</p>\n<h4>Monte Carlo Acquisition for Parallelizing Bayesian Optimization</h4>\n<p>More than just parallelizing batches, we want to figure out what x_next\u00a0is.</p>\n<p>This sequential strategy leverages Gaussian process to compute Monte Carlo estimates of acquisition functions on pending locations. The evaluated data\u00a0is</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/85/0*YeeVEnBZJVH47L0p\"></figure><p>and the pending data\u00a0is</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/56/0*fhK9xDHdi7fbeKxp\"></figure><p>We can use the acquisition function that characterizes the expectation of <strong>a</strong> based on the J-dimensional Gaussian distribution.</p>\n<h3><strong>DeepSwarm</strong></h3>\n<p>The following is a summary of <a href=\"https://arxiv.org/pdf/1905.07350.pdf\">DeepSwarm: Optimizing Convolutional Neural Networks using Swarm Intelligence</a>.</p>\n<h4>Motivation for using\u00a0ACO</h4>\n<ul>\n<li>Swarm intelligence algorithms like ACO are good for neural architecture search due to fault tolerance, decentralization, scalability, and knowledge sharing and combining</li>\n<li>ACO is good at solving discrete problems that have graph representations and can adapt to dynamically changing\u00a0graphs</li>\n<li>A neural network is a type of graph and that is the intuition behind using\u00a0ACO</li>\n</ul>\n<h4>DeepSwarm</h4>\n<ol><li>Creates internal graph with 1 input node at the\u00a0start</li></ol>\n<p>2. Each ant placed on the input\u00a0node</p>\n<p>3. Use Ant Colony System selection rule to select node for next layer of neural\u00a0network</p>\n<ul><li>pheromone value on edge (r,u)\u00a0=</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/49/0*2mr3UOHRlDjKgyxq\"></figure><ul><li>heuristic value on edge (r,u)\u00a0=</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/48/0*Jwmndc42sGSUk5uK\"></figure><ul>\n<li>Jk(r) = nodes available to visit from\u00a0r</li>\n<li>\n<em>q</em> = random # from\u00a0[0,1]</li>\n<li>\n<em>q0</em> in (0,1] = controls greediness of algorithm</li>\n<li>\n<em>Beta</em> in (0, inf) = relative importance of heuristic info</li>\n<li><strong>Selection rule is the following:</strong></li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/436/0*LFG-VYN8eAIOqpJ9\"></figure><ul><li>Where S is a random variable selected from the following distribution:</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/284/0*IguUKmttPEqrFTuR\"></figure><ul><li>If the node is a new one that didn\u2019t exist on the graph, add it as a\u00a0neighbor</li></ul>\n<p>4. After selection rule for a node, each ant will select node attributes like filter size, kernel size, etc using the same\u00a0rule</p>\n<p>5. After both selections, node is added to that ant\u2019s\u00a0path</p>\n<p>6. When ant reaches maximum depth, that neural network architecture is evaluated</p>\n<p>7. <strong>Local Pheromone Update</strong>\u200a\u2014\u200aafter each ant finishes a walk, update every edge in its\u00a0path</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/229/0*aDGfNonD-RD92sAa\"></figure><ul>\n<li>Rho is the pheromone decay factor\u200a\u2014\u200awhen rho is 1, 100% decay so only based on starting value; when rho is 0, the pheromones keep adding up, making the strongest path stronger.</li>\n<li>This rule allows for decay, which encourages ants to find other\u00a0paths</li>\n</ul>\n<p><strong>8. Global Pheromone Update</strong></p>\n<ul>\n<li>After all ants (NNs evaluated), the best ant is found (best NN accuracy)</li>\n<li>Increase pheromone value in best path/tour with the following:</li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/408/0*sGZrGXQgiuk8RDCv\"></figure><ul>\n<li>Alpha is pheromone evaporation rate from\u00a0(0,1)</li>\n<li>Cgb is cost of best tour = best model\u00a0accuracy</li>\n</ul>\n<p>9. After current maximum depth is increased, new population of ants\u00a0created</p>\n<ul><li>Repeat this process until the global maximum depth is\u00a0reached</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/729/0*ku7boz46gya9EiPs\"></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bd500c8398ce\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/geekculture/optimization-techniques-for-ml-models-bd500c8398ce\">Optimization Techniques for ML Models</a> was originally published in <a href=\"https://medium.com/geekculture\">Geek Culture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","content":"\n<p>There are two main areas we can optimize over for many machine learning algorithms and deep learning networks. One is hyperparameters and the second is neural network architecture.</p>\n<p>The selection of hyperparameters is sometimes critical in determining a model\u2019s convergence. Optimization techniques are used to determine what the best hyperparameters are for the learning algorithm. The optimal hyperparameters that correspond to a user defined metric are chosen. Often times optimization is done to minimize the loss of the model or maximize an accuracy. This procedure is known as <strong>Hyperparameter Optimization (HPO).</strong></p>\n<p>Hyperparameter optimization is done over a fixed architecture, but we can also perform a technique called <strong>Network Architecture Search (NAS)</strong>, which performs a search over the architecture space of a ML model or a deep learning network if the model still does not seem to converge after HPO alone. Many times, finding the best architecture can require domain expertise and can be time consuming considering the training and evaluation of multiple versions of the ML model being tested. For example, determining whether to expand the width of a network by adding more hidden nodes or add depth to a network by adding more layers is a problem that can be solved by\u00a0NAS.</p>\n<p>HPO and NAS algorithms can use both white box and black box methods to find the optimal hyperparameters and architecture. White box methods use internal gradients for optimization, so they can typically only be used in models that have a continuous hyperparameter space. Black box methods explore the hyperparameter/architecture space without being concerned about internal gradients so they can be used on any hyperparameter or architecture space. Two black box methods presented below are <a href=\"https://arxiv.org/abs/1206.2944\">Bayesian Optimization</a> and <a href=\"https://arxiv.org/pdf/1905.07350.pdf\">DeepSwarm</a>.</p>\n<h3><strong>Bayesian Optimization</strong></h3>\n<p>The following is a summary of <a href=\"https://papers.nips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf\">Practical Bayesian Optimization of Machine Learning Algorithms</a>.</p>\n<p>The objective of Bayesian Optimization is to find the optimal hyperparameters for a machine learning model. In simple terms this is a unique way to find the minimum of a loss function\u00a0<em>f(x).</em></p>\n<p>This learning algorithm\u2019s generalization performance is modeled as a sample from a Gaussian process (GP). Each GP specified by kernel and hyperparameters and it also takes variable cost and runtime into account for computational parellelization in the\u00a0future.</p>\n<p>Bayesian Optimization is useful for tuning parameters of algorithms that have high computational cost.</p>\n<p>The objective of Bayesian optimization is finding the minimum of <em>f(x)</em> using a probabilistic mode, using all prior evaluations of <em>f(x)</em> to determine location of where to evaluate next instead of local gradients and because evaluations of <em>f(x)</em> are\u00a0costly.</p>\n<p>The two components we need to choose are the Gaussian prior and an acquisition function.</p>\n<h4>Gaussian Process</h4>\n<p>We choose a loss\u00a0function</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/84/0*cWg7dXtYcdqQ7JyQ\"></figure><p>where X is set of hyperparameter settings.</p>\n<p>Then we define a multivariate Gaussian distribution on finite set of N\u00a0points:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/95/0*2i5x3aaCAWoJrbYs\"></figure><p>which induces the distribution on</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/25/0*oGzaWUgqpkhu9dy3\"></figure><p>determined by a mean function and a positive definite covariance function.</p>\n<h4>Acquisition function</h4>\n<p>For the acquisition function we assume data points drawn\u00a0from</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/85/0*J6vzSLtL1ZJBdXrT\"></figure><p>where <em>y</em> is obtained from a normal distribution</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/134/0*8-SgRk_UNxSaNUR5\"></figure><p>and</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/9/0*rpY0_ep6df_hsqCp\"></figure><p>is the variance in the function values. To find the next data point to evaluate in terms of finding the minimum f(x), we\u00a0define</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/159/0*2weJMZycv7QUlZBO\"></figure><p>where <strong>a</strong> represents the acquisition function.</p>\n<p>There are several options to choose from for acquisition function such\u00a0as</p>\n<ul><li>\n<strong>Probability of Improvement\u200a\u2014\u200a</strong>maximize over probability of getting a better value than the best current\u00a0value</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/224/1*9mz9vFNGV2XCEGfDVadsyw.png\"></figure><ul><li>\n<strong>Expected Improvement\u200a\u2014\u200a</strong>maximize expected improvement over current\u00a0best</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/516/1*q-_u1lbZTkPY7Jk-3QRa4Q.png\"></figure><ul><li>Gamma is defined\u00a0as</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/259/1*JqDWftsCGoUibdk42rCMEg.png\"></figure><h4>Modeling costs</h4>\n<p>We need to find best setting of hyperparameters quickly\u200a\u2014\u200awe are more concerned with wall clock time than function progress.</p>\n<p>We optimize with <strong>expected improvement per second</strong>\u200a\u2014\u200apoints that are likely to be good and likely to be evaluated quickly (e.g. choosing from a set of faster learning rates over slower\u00a0ones)</p>\n<h4>Monte Carlo Acquisition for Parallelizing Bayesian Optimization</h4>\n<p>More than just parallelizing batches, we want to figure out what x_next\u00a0is.</p>\n<p>This sequential strategy leverages Gaussian process to compute Monte Carlo estimates of acquisition functions on pending locations. The evaluated data\u00a0is</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/85/0*YeeVEnBZJVH47L0p\"></figure><p>and the pending data\u00a0is</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/56/0*fhK9xDHdi7fbeKxp\"></figure><p>We can use the acquisition function that characterizes the expectation of <strong>a</strong> based on the J-dimensional Gaussian distribution.</p>\n<h3><strong>DeepSwarm</strong></h3>\n<p>The following is a summary of <a href=\"https://arxiv.org/pdf/1905.07350.pdf\">DeepSwarm: Optimizing Convolutional Neural Networks using Swarm Intelligence</a>.</p>\n<h4>Motivation for using\u00a0ACO</h4>\n<ul>\n<li>Swarm intelligence algorithms like ACO are good for neural architecture search due to fault tolerance, decentralization, scalability, and knowledge sharing and combining</li>\n<li>ACO is good at solving discrete problems that have graph representations and can adapt to dynamically changing\u00a0graphs</li>\n<li>A neural network is a type of graph and that is the intuition behind using\u00a0ACO</li>\n</ul>\n<h4>DeepSwarm</h4>\n<ol><li>Creates internal graph with 1 input node at the\u00a0start</li></ol>\n<p>2. Each ant placed on the input\u00a0node</p>\n<p>3. Use Ant Colony System selection rule to select node for next layer of neural\u00a0network</p>\n<ul><li>pheromone value on edge (r,u)\u00a0=</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/49/0*2mr3UOHRlDjKgyxq\"></figure><ul><li>heuristic value on edge (r,u)\u00a0=</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/48/0*Jwmndc42sGSUk5uK\"></figure><ul>\n<li>Jk(r) = nodes available to visit from\u00a0r</li>\n<li>\n<em>q</em> = random # from\u00a0[0,1]</li>\n<li>\n<em>q0</em> in (0,1] = controls greediness of algorithm</li>\n<li>\n<em>Beta</em> in (0, inf) = relative importance of heuristic info</li>\n<li><strong>Selection rule is the following:</strong></li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/436/0*LFG-VYN8eAIOqpJ9\"></figure><ul><li>Where S is a random variable selected from the following distribution:</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/284/0*IguUKmttPEqrFTuR\"></figure><ul><li>If the node is a new one that didn\u2019t exist on the graph, add it as a\u00a0neighbor</li></ul>\n<p>4. After selection rule for a node, each ant will select node attributes like filter size, kernel size, etc using the same\u00a0rule</p>\n<p>5. After both selections, node is added to that ant\u2019s\u00a0path</p>\n<p>6. When ant reaches maximum depth, that neural network architecture is evaluated</p>\n<p>7. <strong>Local Pheromone Update</strong>\u200a\u2014\u200aafter each ant finishes a walk, update every edge in its\u00a0path</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/229/0*aDGfNonD-RD92sAa\"></figure><ul>\n<li>Rho is the pheromone decay factor\u200a\u2014\u200awhen rho is 1, 100% decay so only based on starting value; when rho is 0, the pheromones keep adding up, making the strongest path stronger.</li>\n<li>This rule allows for decay, which encourages ants to find other\u00a0paths</li>\n</ul>\n<p><strong>8. Global Pheromone Update</strong></p>\n<ul>\n<li>After all ants (NNs evaluated), the best ant is found (best NN accuracy)</li>\n<li>Increase pheromone value in best path/tour with the following:</li>\n</ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/408/0*sGZrGXQgiuk8RDCv\"></figure><ul>\n<li>Alpha is pheromone evaporation rate from\u00a0(0,1)</li>\n<li>Cgb is cost of best tour = best model\u00a0accuracy</li>\n</ul>\n<p>9. After current maximum depth is increased, new population of ants\u00a0created</p>\n<ul><li>Repeat this process until the global maximum depth is\u00a0reached</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/729/0*ku7boz46gya9EiPs\"></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bd500c8398ce\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://medium.com/geekculture/optimization-techniques-for-ml-models-bd500c8398ce\">Optimization Techniques for ML Models</a> was originally published in <a href=\"https://medium.com/geekculture\">Geek Culture</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n","enclosure":{},"categories":["optimization"]}]}